{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Dependencies\n",
    "from IPython.display import Image, SVG\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Shape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emnist in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (0.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from emnist) (1.21.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from emnist) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from emnist) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->emnist) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->emnist) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->emnist) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->emnist) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->emnist) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install emnist\n",
    "# Import Dataset(s)\n",
    "from emnist import list_datasets\n",
    "list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with 'letters'\n",
    "# Import \n",
    "from emnist import extract_training_samples\n",
    "images_train, labels_train = extract_training_samples('letters')\n",
    "from emnist import extract_test_samples\n",
    "images_test, labels_test = extract_test_samples('letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124800, 28, 28)\n",
      "(124800,)\n",
      "(20800, 28, 28)\n",
      "(20800,)\n"
     ]
    }
   ],
   "source": [
    "# Check shape of training and testing data\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(images_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25e178e4340>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot an image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images_train[0,:,:], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (124800, 784)\n",
      "Testing Shape: (20800, 784)\n"
     ]
    }
   ],
   "source": [
    "# Flatten Data\n",
    "dims = images_train.shape[1] * images_train.shape[2]\n",
    "X_train = images_train.reshape(images_train.shape[0], dims)\n",
    "X_test = images_test.reshape(images_test.shape[0], dims)\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale to 0 -> 1 by dividing by max pixel value (255)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "from keras.utils import np_utils # used to convert array of labeled data to one-hot vector\n",
    "# should be 26 but out of index?\n",
    "# Effects accuracy as have a class where their will be no results\n",
    "num_classes = 27\n",
    "y_train = np_utils.to_categorical(labels_train, num_classes)\n",
    "y_test = np_utils.to_categorical(labels_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Sequential model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Layers\n",
    "# 1 - number of elements (pixels) in each image\n",
    "# Dense layer - when every node from previous layer is connected to each node in current layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "# Second Hidden Layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "#Third Hidden Layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Output Layer - number of nodes corresponds to number of y labels\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "975/975 [==============================] - 16s 15ms/step - loss: 0.6412 - accuracy: 0.8030\n",
      "Epoch 2/10\n",
      "975/975 [==============================] - 15s 15ms/step - loss: 0.3372 - accuracy: 0.8938\n",
      "Epoch 3/10\n",
      "975/975 [==============================] - 15s 15ms/step - loss: 0.2992 - accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "975/975 [==============================] - 14s 14ms/step - loss: 0.2951 - accuracy: 0.9100\n",
      "Epoch 5/10\n",
      "975/975 [==============================] - 15s 15ms/step - loss: 0.2995 - accuracy: 0.9110\n",
      "Epoch 6/10\n",
      "975/975 [==============================] - 16s 17ms/step - loss: 0.3081 - accuracy: 0.9101\n",
      "Epoch 7/10\n",
      "975/975 [==============================] - 18s 19ms/step - loss: 0.3133 - accuracy: 0.9094\n",
      "Epoch 8/10\n",
      "975/975 [==============================] - 16s 17ms/step - loss: 0.3284 - accuracy: 0.9080\n",
      "Epoch 9/10\n",
      "975/975 [==============================] - 17s 17ms/step - loss: 0.3357 - accuracy: 0.9073\n",
      "Epoch 10/10\n",
      "975/975 [==============================] - 17s 17ms/step - loss: 0.3442 - accuracy: 0.9058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e17ba7dc0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, shuffle=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(\"emnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"emnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (128, 784) for input KerasTensor(type_spec=TensorSpec(shape=(128, 784), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (32, 784).\n",
      "650/650 - 3s - loss: 0.4937 - accuracy: 0.9006 - 3s/epoch - 4ms/step\n",
      "Loss: 0.49368271231651306, Accuracy: 0.9005769491195679\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
